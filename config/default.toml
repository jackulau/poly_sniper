# Polysniper Configuration

# Health check HTTP server
[health]
# Whether the health server is enabled
enabled = true
# Address and port to bind to
bind_address = "127.0.0.1:8080"

[endpoints]
clob_rest = "https://clob.polymarket.com"
clob_ws = "wss://ws-subscriptions-clob.polymarket.com/ws/"
gamma_api = "https://gamma-api.polymarket.com"

[auth]
# Environment variable containing the private key
private_key_env = "POLYMARKET_PRIVATE_KEY"
# Signature type: 0 = EOA wallet, 1 = Poly Proxy, 2 = Poly Gnosis Safe
signature_type = 0

[risk]
# Maximum position size per market in USD
max_position_size_usd = 5000
# Maximum single order size in USD
max_order_size_usd = 500
# Daily loss limit in USD (stops trading when reached)
daily_loss_limit_usd = 500
# Circuit breaker threshold (halts all trading)
circuit_breaker_loss_usd = 300
# Maximum orders per minute
max_orders_per_minute = 60

# Time-based risk rules
# These rules reduce or halt trading activity as market events approach
[risk.time_rules]
enabled = true

# Reduce position size by 50% within 24 hours of resolution
[[risk.time_rules.rules]]
name = "pre_resolution_reduction"
hours_before = 24
action = { type = "reduce_size", multiplier = 0.5 }
applies_to = ["*"]

# Block new positions within 2 hours of resolution (exits still allowed)
[[risk.time_rules.rules]]
name = "resolution_block"
hours_before = 2
action = "block_new"
applies_to = ["*"]

# Example: Apply stricter rules to election markets
# [[risk.time_rules.rules]]
# name = "election_early_block"
# hours_before = 12
# action = "block_new"
# applies_to = ["*election*", "*vote*"]

[execution]
# Set to true to log orders without actually submitting
dry_run = true
# Number of retry attempts for failed orders
max_retries = 3
# Delay between retries in milliseconds
retry_delay_ms = 100

# Queue Position Estimation
[execution.queue_estimation]
# Whether queue estimation is enabled
enabled = true
# How far back to look for fill rates (in seconds)
history_window_secs = 300
# Minimum fills needed for reliable estimation
min_samples_for_estimate = 10
# How quickly confidence decays with time (0.0 to 1.0)
confidence_decay_factor = 0.95

# Phase 5: SQLite Persistence
[persistence]
# Whether persistence is enabled
enabled = true
# Path to SQLite database file
db_path = "data/polysniper.db"
# Price snapshot interval in seconds
price_snapshot_interval_secs = 60
# Maximum price snapshots to keep per token
max_price_snapshots = 10000

# Phase 6: Prometheus Metrics
[metrics]
# Whether metrics are enabled
enabled = true
# Port for metrics HTTP server (accessible at http://localhost:9090/metrics)
port = 9090
# Collection interval in seconds
collection_interval_secs = 60

# Phase 7: Alerting
[alerting]
# Whether alerting is enabled
enabled = true
# Minimum alert level to send (info, warning, critical)
min_level = "warning"
# Rate limit between duplicate alerts in seconds
rate_limit_seconds = 60

# Slack webhook configuration
[alerting.slack]
enabled = false
webhook_url = ""
channel = "#polysniper-alerts"
username = "Polysniper"
icon_emoji = ":chart_with_upwards_trend:"

# Telegram bot configuration
[alerting.telegram]
enabled = false
bot_token = ""
chat_id = ""
parse_mode = "HTML"

# Feed Ingestion for Sentiment Analysis
[feeds]
# Whether feed ingestion is enabled
enabled = false
# Global keywords to track across all sources
keywords = ["polymarket", "prediction market", "kalshi"]
# Maximum items to keep in deduplication cache
dedup_cache_size = 10000

# Twitter API configuration
[feeds.twitter]
enabled = false
# Environment variable containing the Twitter Bearer Token
bearer_token_env = "TWITTER_BEARER_TOKEN"
# Polling interval in seconds (min 60 to respect rate limits)
poll_interval_secs = 60
# Maximum results per query (max 100)
max_results = 100

# Twitter search queries to monitor
[[feeds.twitter.queries]]
query = "polymarket"
include_retweets = false

[[feeds.twitter.queries]]
query = "prediction market"
include_retweets = false

# RSS/Atom feed configuration
[feeds.rss]
enabled = false
# Polling interval in seconds
poll_interval_secs = 300
# Request timeout in seconds
timeout_secs = 30

# RSS feeds to monitor
# [[feeds.rss.feeds]]
# url = "https://example.com/feed.xml"
# name = "Example Feed"
# keywords = []  # Empty means all items
